+++
date = '2025-05-11T12:50:42-04:00'
draft = true
title = 'Legion Intro'
+++

I ran into a little bit of a problem with my crypto platform. Well, a big problem... Actually, it was a lot of problems. Where to even begin here?

Anyone who has made an algorithm knows that the key to success is utilizing weights to dynamically adjust their formula to adhere to the latest data available to the system. Those doing this algorithmically can take it a step further and sometimes even adjust the formula itself based on the weights being present. Maybe RSI is too slow, so we can use a faster indicator. Maybe the market is trending, so we can use a trend following indicator. Maybe the market is ranging, so we can use a mean reversion indicator. It's still mostly the same formula, but small pieces can change to deliver a different score. 

With a crypto algorithm, this meant that no matter the market conditions, I was still using the same math to handle all data even if I allowed the system to change its weights and slightly adjust the math. The problem is that if I let it alter the math, then the formula is brand new again and I have to completely backtest it. Doing this every day was a nightmare. I was retraining AI models every day, but the longer the day went on, the more out of data the data and its corresponding model was. Of course, I can just keep retraining my AI models throughout the day, but there's no way I'm going to foot the bill to train up to 24 AI models every day.

Then, there was also the problem of adjusting the formula based on real world events. You see, you don't want the AI system to be formulating opinions when you're dealing with mathematical formulas. Me, being the naive programming crypto investor that I am, foolishly thought that by bringing in real world events into the formulaic system, that I could produce better scores by treating these real world events as a mathematical weight. The problem is, how do you treat that data with a mathmetical score? If the President announces a new policy, how do you mathematically represent that? You can't just say something is good or bad, you have to take into the account the person that it's affecting. What profits for one person could be a disaster for another. This means that my formula can only work for one person, me, and no one else. This is because I have to either train a model about me and my circumstances, or I'd have to mathematically represent what factors into something being good or bad for myself in code. And I did try doing that, but it was terrible. It ended up being a ranked system that I had to anticipate (I actually used generative AI to come up with scenarios), but then I had to score them and honestly, it was all extremely subjective.

So, I took a step back. I then went back to my data and I took a look at what I was storing in there to help me system make decisions. Surely, there were more features I could derive from the initial core data ingestion payloads and that would fix everything. And... it did not. In fact, the more I looked at the data I collected, the more I was becoming increasingly frustrated. I then took another step back, and another... and then another. It got to the point I had to pull up my old architecture diagram I posted here a while back and study it, which was interesting because I'm the one who made it in the first place.

What I saw was a really good attempt at algorithmic trading, and then I realized that my problem here was everything. I was trying to create an algorithmic trading system that used historical data to make preditcions about the future. In this kind of market where volatility is at all time highs from out of market influences, I need something different.

And so this is why you haven't heard from me in a bit. I needed to start from scratch and build something new. I'm really glad I started building Crypto Compass and then the auto-trader that it slowly morphed into because I learned a lot from that. Mostly, what not to do, but I was able to build on a lot of skills that I'd only briefly touch on at work throughout these projects. But, I ultimately realized that I need to do something different that had not been done before. It meant leaving the safety of the r/algotrading subreddit I'd been using to help speed things along when building the algorithm. It also meant leaving a lot of documentation that much smarter people than me had written about using algorithms on active markets. What I've planned out here and started building is something I don't think anyone has seen before.

Have you ever seen the TV show Legion? Maybe you're more familiar with the comic book series about him? Well, Legion is a superhero with a split personality. He might be one super hero, but he has so many personalities inside his head, that to carry out one action, he actually has a bunch of voices in his head consulting each other to figure out how or what to do. And I really like that idea. Why have one system come up with a decision when you can have a bunch of systems talk to each other and come to a consensus? If system A thinks its time to act on an indicator, but system B thinks that the indicator isn't right, is it possible to have a system where both could be right until they talk to each other and come to a consensus?

Some of you who are AI experts already might be catching on that I'm beginning to describe a multi-agent system, commonly referred to as Agent2Agent (A2A). The idea behind it is basically to have individual agents with unique tasks each specializes in all talk to each other and come to a consensus. It's basically still a formula, but I'm giving AI systems a chance to have more improvisational opportunities. Of course, this breeds inconsistency, but that's where Legion comes in.

When algorighmic trading happens, you create an event that triggers at that moment and derives a score of what to do, usually buy or sell. This is called event driven architecture. An event happens, code triggers, and an action is taken. Legion doesn't do that.

In fact, Legion doesn't have a trigger. There is no event telling Legion to go do anything. Legion is a system that is always running and always listening. Algorithmic trading essentially creates an entrypoint into the market and then exit points are caclulated based on your entrypoint, but Legion's entrypoint is just the moment I turn on the system. Instead, Legion acts as a day trader and decides on its own frequencies of entering the market and leaving. Its design doesn't use a buy signal to determine exit points, it's already in the market even if it's not bought into the market.

If you're confused, good, because this is a new idea. This isn't an AI bot making decisions on your behalf, it's a system of interconnected agents each talking to each other. There isn't even a predetermined order to the conversation and yes, there is a literal conversation happening inside of Legion. 

One of the cool things about working with AI agents is creating tools for the agent. You basically give it access to a function, API, maybe even an MCP server, and then you tell the agent if a user says something related to a specific pattern that the agent should call that function. My idea is along those lines. Instead of there being a user that tells the agent what to do, the agents themselves will actually trigger each other depending on the prompt being made.

It's kind of messy when you first start thinking about it. There's so many edge cases to work out. The first one I thought of was recursion; what if agents get stuck in a loop where they keep calling each other and no decision is made? This is where guardrails are really important because I have to make sure that loops can't happen. And maybe, it's not even a guardrail that prevents loops, but an entire agent itself dedicated to breaking loops. With this kind of flexibility, the skies the limit for how this system can operate.

Legion literally breaks the mold by doing the exact thing you're not supposed to do when using code to trade on financial markets; improvise. The algorithm I had before took historical data to derive a score. Any time you ran that data and gave it the same inputs, the same score should come out every time. Legion takes in those same inputs, but because of its ability to take the data and converse with other agents, it doesn't create a score. It creates reason. Once reason is created, it then looks for consensus. Once consensus is achieved, then an action is taken.

My next blog post will be about the agentic framework I've created that each agent would follow. They're system instructions given to the agents that tell them how to interact with each other. While each agent will be given a unique set of instructions, they're are common prompts I'll be using to guide the conversation and ensure the agents operate within the confines of what I need them to do. While I do want to foster improvisation, I need to make sure that kind of unpredictability is boxed in so that I can trust and rely on the system. I have also ditched the weekly release schedule of blog posting as that was way too much to keep up with while having a full time job, life, and side projects like this one. So, tune in next time, whenever that is, where I tell you tips and tricks of how to make an AI agent improvise with data, but stay trustworthy and avoid saying something that isn't true.